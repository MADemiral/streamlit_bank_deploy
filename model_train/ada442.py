# -*- coding: utf-8 -*-
"""Ada442.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11fFYav4H2XZxV_vYFvot8Ip97-FnBE7v

# Import Modules
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
# %matplotlib inline
warnings.filterwarnings('ignore')

"""# Load Dataset"""

df = pd.read_csv('bank.csv')
df.head()

# statistical info
df.describe()

# datatype info
df.info()

df.columns

#shape of dataset
df.shape

df.tail()

df.duplicated().sum()

numerical_columns = df.select_dtypes(include=np.number).columns
numerical_columns

categorical_columns = df.select_dtypes(include='object').columns
categorical_columns

for var in categorical_columns:
    print(df[var].value_counts())
    print('__'*45)

"""# Exploratory Data Analysis"""

from scipy.stats import norm
for var in numerical_columns:
    plt.figure(figsize=(15,6))
    plt.subplot(1,2,1)
    ax=sns.boxplot(data=df[var])
    ax.set_title(f'{var}')
    ax.set_ylabel(var)

    plt.subplot(1,2,2)
    ax=sns.distplot(df[var], fit=norm)
    ax.set_title(f'skewness of {var} : {df[var].skew()}')
    ax.set_xlabel(var)
    print('__'*45)


for cat in categorical_columns:
    df[cat].hist(figsize=(15,6))


"""# Preprocessing the dataset"""

df = df.replace('unknown', np.nan)

#checking for null values
df.isnull().sum()

#checking for NA values
df.isna().sum()

nulls=pd.DataFrame(df.isna().sum().sort_values(ascending=False)/len(df),columns=['percentage'])
nulls

"""# Imputation

"""

from sklearn.compose import make_column_transformer
from sklearn.impute import SimpleImputer, KNNImputer
from sklearn.preprocessing import OneHotEncoder,LabelEncoder, OrdinalEncoder, MinMaxScaler, StandardScaler, RobustScaler

most_frequent_imputer = SimpleImputer(strategy='most_frequent')
df_copy = df.copy()

for col in categorical_columns:
  df_copy[[col]] = most_frequent_imputer.fit_transform(df_copy[[col]])

categories = ["illiterate", "basic.4y", "basic.6y", "basic.9y",
              "high.school", "professional.course", "university.degree"]


ordinal_encoder = OrdinalEncoder(categories=[categories])
df_copy['education'] = ordinal_encoder.fit_transform(df_copy[['education']])

cat = categorical_columns.drop('education')
cat = categorical_columns.drop('y')
onehot_encoder = OneHotEncoder(drop='first',sparse_output=False)
encoded = onehot_encoder.fit_transform(df_copy[cat])
one_hot_df = pd.DataFrame(encoded, columns=onehot_encoder.get_feature_names_out(cat))
df_sklearn_encoded = pd.concat([df_copy.drop(cat, axis=1), one_hot_df], axis=1)
df_sklearn_encoded.head()
df_sklearn_encoded.select_dtypes(include='object').columns

"""# Coorelation Matrix"""

df_numeric = df.select_dtypes(include=[np.number])

corr = df_numeric.corr()
plt.figure(figsize=(18, 18))
sns.heatmap(corr, annot=True, cmap='coolwarm')


"""# Model Training , Hyper Parameter Tuning and Evolution


"""
# -*- coding: utf-8 -*-
"""Ada442.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11fFYav4H2XZxV_vYFvot8Ip97-FnBE7v

# Import Modules
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler
from sklearn.feature_selection import SelectKBest, f_classif
from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, confusion_matrix
import pickle

# Suppress warnings
warnings.filterwarnings('ignore')

# Load Dataset
df = pd.read_csv('bank.csv')
df.head()

# Preprocessing steps, imputation, etc. (similar to the code you've already written)

# Prepare data
X = df_sklearn_encoded.drop('y', axis=1)
y = df_sklearn_encoded['y']

# Split data into train and test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize scalers
scalers = [StandardScaler(), MinMaxScaler(), RobustScaler()]
pipelines = {}

# Create pipelines for different models
for scaler in scalers:
    scaler_name = scaler.__class__.__name__
    pipelines[f'knn_{scaler_name}'] = Pipeline([
        ('scaler', scaler),
        ('feature_selection', SelectKBest(score_func=f_classif, k=2)),
        ('knn', KNeighborsClassifier())
    ])
    pipelines[f'log_reg_{scaler_name}'] = Pipeline([
        ('scaler', scaler),
        ('feature_selection', SelectKBest(score_func=f_classif, k=2)),
        ('log_reg', LogisticRegression(max_iter=1000))
    ])
    pipelines[f'svm_{scaler_name}'] = Pipeline([
        ('scaler', scaler),
        ('feature_selection', SelectKBest(score_func=f_classif, k=2)),
        ('svm', SVC())
    ])
pipelines['decision_tree'] = Pipeline([
    ('feature_selection', SelectKBest(score_func=f_classif, k=2)),
    ('decision_tree', DecisionTreeClassifier())
])
pipelines['random_forest'] = Pipeline([
    ('feature_selection', SelectKBest(score_func=f_classif, k=2)),
    ('random_forest', RandomForestClassifier())
])

# Grid search parameters
grid_params = {
    'knn_StandardScaler': {
        'knn__n_neighbors': [3, 5, 7, 9],
        'knn__weights': ['uniform', 'distance']
    },
    'knn_MinMaxScaler': {
        'knn__n_neighbors': [3, 5, 7, 9],
        'knn__weights': ['uniform', 'distance']
    },
    'knn_RobustScaler': {
        'knn__n_neighbors': [3, 5, 7, 9],
        'knn__weights': ['uniform', 'distance']
    },
    'log_reg_StandardScaler': {
        'log_reg__C': [0.1, 1, 10],
        'log_reg__penalty': ['l2'],
        'log_reg__solver': ['lbfgs']
    },
    'log_reg_MinMaxScaler': {
        'log_reg__C': [0.1, 1, 10],
        'log_reg__penalty': ['l2'],
        'log_reg__solver': ['lbfgs']
    },
    'log_reg_RobustScaler': {
        'log_reg__C': [0.1, 1, 10],
        'log_reg__penalty': ['l2'],
        'log_reg__solver': ['lbfgs']
    },
    'decision_tree': {
        'decision_tree__max_depth': [None, 5, 10, 20],
        'decision_tree__min_samples_split': [2, 5, 10]
    },
    'random_forest': {
        'random_forest__n_estimators': [50, 100, 200],
        'random_forest__max_depth': [None, 5, 10],
        'random_forest__min_samples_split': [2, 5, 10]
    },
    'svm_StandardScaler': {
        'svm__C': [0.1, 1, 10],
        'svm__kernel': ['linear', 'rbf']
    },
    'svm_MinMaxScaler': {
        'svm__C': [0.1, 1, 10],
        'svm__kernel': ['linear', 'rbf']
    },
    'svm_RobustScaler': {
        'svm__C': [0.1, 1, 10],
        'svm__kernel': ['linear', 'rbf']
    }
}

# Initialize variables for best models and scores
best_models = {}
best_scores = {}
best_f1_scores = {}

# Cross-validation setup
kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# Grid search for each model
for name, pipeline in pipelines.items():
    print(f"\nRunning GridSearchCV for {name}...")
    grid_search = GridSearchCV(pipeline, grid_params[name], cv=kf, scoring='accuracy', n_jobs=-1)
    grid_search.fit(X_train, y_train)
    
    best_models[name] = grid_search.best_estimator_
    best_scores[name] = grid_search.best_score_
    
    y_pred = grid_search.best_estimator_.predict(X_test)
    f1 = f1_score(y_test, y_pred, average='weighted')
    best_f1_scores[name] = f1
    
    print(f"Best parameters for {name}: {grid_search.best_params_}")
    print(f"Best cross-validated accuracy for {name}: {grid_search.best_score_:.4f}")
    print(f"Test set F1 score for {name}: {f1:.4f}")

# Sort models by accuracy scores in descending order
sorted_models = sorted(best_scores.items(), key=lambda x: x[1], reverse=True)

# Save the top 3 models directly
for rank, (model_name, accuracy_score) in enumerate(sorted_models[:3], start=1):
    model_f1_score = best_f1_scores[model_name]
    model = best_models[model_name]
    
    # Get selected features
    feature_selector = model.named_steps.get('feature_selection')
    if feature_selector:
        selected_features_indices = feature_selector.get_support(indices=True)
        selected_features_names = [X.columns[i] for i in selected_features_indices]
    else:
        selected_features_names = []
    
    # Create filename
    filename = f"Model{rank}_{model_name}_accuracy_{accuracy_score:.4f}_f1_{model_f1_score:.4f}.pkl"
    
    # Save the model
    with open(filename, 'wb') as f:
        pickle.dump(model, f)  # Save the model directly
    
    print(f"Saved model {rank}: {filename}")

# Identify and print the best model
best_model_name = max(best_f1_scores, key=best_f1_scores.get)
print(f"\nBest model: {best_model_name} with F1 score: {best_f1_scores[best_model_name]:.4f}")

# Evaluate the best model on the test set
test_score = best_models[best_model_name].score(X_test, y_test)
print(f"\nTest set accuracy for best model ({best_model_name}): {test_score:.4f}")

y_pred_best = best_models[best_model_name].predict(X_test)
precision = precision_score(y_test, y_pred_best, average='weighted')
recall = recall_score(y_test, y_pred_best, average='weighted')
f1 = f1_score(y_test, y_pred_best, average='weighted')
conf_matrix = confusion_matrix(y_test, y_pred_best)

print(f"\nPrecision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1 Score: {f1:.4f}")
print(f"Confusion Matrix:\n{conf_matrix}")

# Get selected features for the best model
feature_selector = best_models[best_model_name].named_steps['feature_selection']
selected_features_indices = feature_selector.get_support(indices=True)
selected_features = X.columns
selected_features_names = [selected_features[i] for i in selected_features_indices]

print(f"\nSelected features for the best model ({best_model_name}): {selected_features_names}")

# Save the best model with its selected features
with open('best_model.pkl', 'wb') as f:
    pickle.dump(best_models[best_model_name], f)

print("\nBest model saved as 'best_model.pkl'")




